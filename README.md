This is a little project that I just followed along in youtube to gain more understanding on the math behind neural networks. For this project specifically, we utilized the ReLU and softmax activation 
function in our three layer neural network (1 input and two hidden). 


Youtube video link: https://www.youtube.com/watch?v=w8yWXqWQYmU&t=996s&ab_channel=SamsonZhang
